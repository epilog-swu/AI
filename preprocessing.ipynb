{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./D01/-------------------------------------------------------------------------------\n",
      "Successfully converted ./D01/D01_SA14_R01.txt to ./D01/D01_SA14_R01.csv\n",
      "0/250\n",
      "Successfully converted ./D01/D01_SE02_R01.txt to ./D01/D01_SE02_R01.csv\n",
      "0/250\n",
      "Successfully converted ./D01/D01_SA15_R01.txt to ./D01/D01_SA15_R01.csv\n",
      "0/250\n",
      "Successfully converted ./D01/D01_SA17_R01.txt to ./D01/D01_SA17_R01.csv\n",
      "0/250\n",
      "Successfully converted ./D01/D01_SE01_R01.txt to ./D01/D01_SE01_R01.csv\n",
      "0/450\n",
      "Successfully converted ./D01/D01_SA16_R01.txt to ./D01/D01_SA16_R01.csv\n",
      "0/250\n",
      "Successfully converted ./D01/D01_SA13_R01.txt to ./D01/D01_SA13_R01.csv\n",
      "0/250\n",
      "Successfully converted ./D01/D01_SA12_R01.txt to ./D01/D01_SA12_R01.csv\n",
      "0/250\n",
      "Successfully converted ./D01/D01_SA09_R01.txt to ./D01/D01_SA09_R01.csv\n",
      "0/250\n",
      "Successfully converted ./D01/D01_SA10_R01.txt to ./D01/D01_SA10_R01.csv\n",
      "0/250\n",
      "Successfully converted ./D01/D01_SA11_R01.txt to ./D01/D01_SA11_R01.csv\n",
      "0/250\n",
      "Successfully converted ./D01/D01_SA18_R01.txt to ./D01/D01_SA18_R01.csv\n",
      "0/250\n",
      "./D01/ fall_detected_count=0/3200, group_zero_count=12/12\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import websocket\n",
    "\n",
    "cnt = 10\n",
    "title = f\"fall_detection_results_{cnt}\"\n",
    "subtitle = \"ASVM: 4.5 (60) GSVM: 1.5 (30) angleY: 90 && angleX: 90 (20)\"\n",
    "# directories = ['./D01/', './D05/', './D12/', './D14/', './F01/', './F02/','./F08/','./F09/','./F13/','./F15/']\n",
    "directories = ['./D01/']\n",
    "ws_url = 'ws://localhost:8080/detection/fall?token={token}'\n",
    "column_names = ['accX', 'accY', 'accZ', 'gyroX', 'gyroY', 'gyroZ', 'acc2X', 'acc2Y', 'acc2Z']\n",
    "acc_scaling_factor = 0.0383\n",
    "gyro_scaling_factor = 0.01\n",
    "results = []\n",
    "results.append(subtitle)\n",
    "\n",
    "def convert_txt_to_csv(txt_path, csv_path):\n",
    "    try:\n",
    "        df = pd.read_csv(txt_path, header=None, delimiter=',')\n",
    "        df.columns = column_names\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\"Successfully converted {txt_path} to {csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to convert {txt_path} to {csv_path}: {e}\")\n",
    "\n",
    "def process_csv_file(csv_path):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        if df.shape[1] < 3:\n",
    "            raise ValueError(f\"File {csv_path} does not contain enough columns.\")\n",
    "\n",
    "        # Scaling accelerometer and gyroscope data\n",
    "        df[['accX', 'accY', 'accZ']] = df[['accX', 'accY', 'accZ']] * acc_scaling_factor\n",
    "        df[['gyroX', 'gyroY', 'gyroZ']] = df[['gyroX', 'gyroY', 'gyroZ']] * gyro_scaling_factor\n",
    "\n",
    "        # Rounding the values for better readability\n",
    "        df = df.round({'accX': 2, 'accY': 2, 'accZ': 2, 'gyroX': 2, 'gyroY': 2, 'gyroZ': 2})\n",
    "        \n",
    "        fall_data = df.iloc[:, :6]\n",
    "        fall_data.columns = [\"accX\", \"accY\", \"accZ\", \"gyroX\", \"gyroY\", \"gyroZ\"]\n",
    "        fall_data = fall_data.to_dict(orient=\"records\")\n",
    "        \n",
    "        return fall_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {csv_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def split_data(data, chunk_size=80):\n",
    "    for i in range(0, len(data), chunk_size):\n",
    "        yield data[i:i + chunk_size]\n",
    "\n",
    "def send_json_via_websocket(json_data, url):\n",
    "    try:\n",
    "        ws = websocket.WebSocket()\n",
    "        ws.connect(url)\n",
    "        ws.send(json.dumps(json_data))\n",
    "        response = ws.recv()\n",
    "        ws.close()\n",
    "        \n",
    "        response_data = json.loads(response)\n",
    "        if response_data.get(\"event\") == \"fall\":\n",
    "            success = response_data.get(\"success\")\n",
    "            return success\n",
    "        else:\n",
    "            print(f\"Unexpected response: {response}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to send data via WebSocket: {e}\")\n",
    "        return False\n",
    "\n",
    "for directory in directories:\n",
    "    print(f\"{directory}-------------------------------------------------------------------------------\")\n",
    "    txt_file_paths = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith('.txt')]\n",
    "    total_cnt = 0\n",
    "    total_success = 0\n",
    "    total_zero = 0\n",
    "    total_group = 0\n",
    "    for txt_file_path in txt_file_paths:\n",
    "        count = 0\n",
    "        success_cnt = 0\n",
    "        csv_file_path = txt_file_path.replace('.txt', '.csv')\n",
    "        convert_txt_to_csv(txt_file_path, csv_file_path)\n",
    "        \n",
    "        fall_data = process_csv_file(csv_file_path)\n",
    "        \n",
    "        if fall_data is None:\n",
    "            continue\n",
    "        \n",
    "        chunks = list(split_data(fall_data, chunk_size=80))\n",
    "        \n",
    "        for idx, chunk in enumerate(chunks):\n",
    "            json_data = {\n",
    "                \"event\": \"fall\",\n",
    "                \"data\": {\n",
    "                    \"fall\": chunk\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            json_file_path = txt_file_path.replace('.txt', f'_{idx}.json')\n",
    "            with open(json_file_path, 'w') as f:\n",
    "                json.dump(json_data, f, indent=4)\n",
    "            \n",
    "            success = send_json_via_websocket(json_data, ws_url)\n",
    "            count += 1\n",
    "            if success:\n",
    "                success_cnt += 1\n",
    "        print(f\"{success_cnt}/{count}\")\n",
    "        total_group += 1\n",
    "        if success_cnt==0:\n",
    "            total_zero += 1\n",
    "        total_success += success_cnt\n",
    "        total_cnt += count\n",
    "    result = f\"{directory} fall_detected_count={total_success}/{total_cnt}, group_zero_count={total_zero}/{total_group}\"\n",
    "    print(result)\n",
    "    results.append(result)\n",
    "\n",
    "with open(title, 'w') as f:\n",
    "    for result in results:\n",
    "        f.write(result + '\\n')\n",
    "\n",
    "print(\"End\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './fall_detection_results_9'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m group_zero_counts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m total_groups \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     15\u001b[0m     lines \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './fall_detection_results_9'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 파일 경로\n",
    "file_path = \"./fall_detection_results_9\"\n",
    "\n",
    "# 데이터 읽기 및 파싱\n",
    "directories = []\n",
    "fall_detected_counts = []\n",
    "total_counts = []\n",
    "group_zero_counts = []\n",
    "total_groups = []\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        if \"fall_detected_count\" in line:\n",
    "            parts = line.split()\n",
    "            directory = parts[0]\n",
    "            fall_detected_count = int(parts[1].split('=')[1].split('/')[0])\n",
    "            total_count = int(parts[1].split('=')[1].split('/')[1].split(',')[0])\n",
    "            group_zero_count = int(parts[2].split('=')[1].split('/')[0])\n",
    "            total_group = int(parts[2].split('=')[1].split('/')[1])\n",
    "            \n",
    "            directories.append(directory)\n",
    "            fall_detected_counts.append(fall_detected_count)\n",
    "            total_counts.append(total_count)\n",
    "            group_zero_counts.append(group_zero_count)\n",
    "            total_groups.append(total_group)\n",
    "\n",
    "# 데이터프레임 생성\n",
    "data = {\n",
    "    \"directory\": directories,\n",
    "    \"fall_detected_count\": fall_detected_counts,\n",
    "    \"total_count\": total_counts,\n",
    "    \"group_zero_count\": group_zero_counts,\n",
    "    \"total_group\": total_groups\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 시각화 및 저장\n",
    "\n",
    "# 낙상 감지 횟수 시각화\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.bar(df['directory'], df['fall_detected_count'], color='blue', alpha=0.7, label='Fall Detected Count')\n",
    "# plt.xlabel('Directory')\n",
    "# plt.ylabel('Fall Detected Count')\n",
    "# plt.title('Fall Detected Count per Directory')\n",
    "# plt.legend()\n",
    "# plt.savefig(f'./fall_detected_count_per_directory_{cnt}.png')\n",
    "# plt.show()\n",
    "\n",
    "# 그룹 제로 카운트 시각화\n",
    "df['group_zero_ratio'] = df['group_zero_count'] / df['total_group']\n",
    "print(df)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['directory'], df['group_zero_ratio'], color='red', alpha=0.7, label='Group Zero Count')\n",
    "plt.xlabel('Directory')\n",
    "plt.ylabel('Group Zero Ratio')\n",
    "plt.title('Group Zero Count ratio Directory')\n",
    "plt.legend()\n",
    "plt.savefig(f'./group_zero_ratio_per_directory_{cnt}.png')\n",
    "plt.show()\n",
    "\n",
    "# 낙상 감지 비율 시각화\n",
    "df['fall_detected_ratio'] = df['fall_detected_count'] / df['total_count']\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['directory'], df['fall_detected_ratio'], color='green', alpha=0.7, label='Fall Detected Ratio')\n",
    "plt.xlabel('Directory')\n",
    "plt.ylabel('Fall Detected Ratio')\n",
    "plt.title('Fall Detected Ratio per Directory')\n",
    "plt.legend()\n",
    "plt.savefig(f'./fall_detected_ratio_per_directory_{cnt}.png')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
